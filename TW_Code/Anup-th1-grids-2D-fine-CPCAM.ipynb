{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/anup.das/.conda/envs/py3_env/lib/python3.7/site-packages/ptsa/data/readers/index.py:39: FutureWarning: Lab-specific readers may be moved to the cmlreaders package (https://github.com/pennmem/cmlreaders)\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats, signal\n",
    "from scipy.signal import hilbert\n",
    "from numpy.lib.recfunctions import append_fields, merge_arrays\n",
    "from nilearn import plotting\n",
    "from pycircstat import mean as circmean\n",
    "import pycircstat\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from tarjan import tarjan\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "import matplotlib.colors as clrs\n",
    "import matplotlib.cm as cmx\n",
    "import nilearn.plotting as ni_plot\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pylab as pyl\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from SubjectLevel.par_funcs_fine import *\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from ptsa.data.readers import EEGReader\n",
    "from ptsa.data.filters import ResampleFilter\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import cluster_helper.cluster\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>montage</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1076D</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1147P</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1154D</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1155D</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1156D</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R1167M</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R1184M</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R1190P</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R1201P</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R1202M</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R1222M</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R1226D</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R1234D</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R1251M</td>\n",
       "      <td>0</td>\n",
       "      <td>RAM_TH1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  montage     task\n",
       "0   R1076D        0  RAM_TH1\n",
       "1   R1147P        0  RAM_TH1\n",
       "2   R1154D        0  RAM_TH1\n",
       "3   R1155D        0  RAM_TH1\n",
       "4   R1156D        0  RAM_TH1\n",
       "5   R1167M        0  RAM_TH1\n",
       "6   R1184M        0  RAM_TH1\n",
       "7   R1190P        0  RAM_TH1\n",
       "8   R1201P        0  RAM_TH1\n",
       "9   R1202M        0  RAM_TH1\n",
       "10  R1222M        0  RAM_TH1\n",
       "11  R1226D        0  RAM_TH1\n",
       "12  R1234D        0  RAM_TH1\n",
       "13  R1251M        0  RAM_TH1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get TH1 subjects\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "subjs=RAM_helpers.get_subjs_and_montages('RAM_TH1')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "#Find subjects with only grids electrodes\n",
    "Count_Grids = np.empty(0)\n",
    "for i in range(0,np.shape(subjs)[0],1):\n",
    "    subject = subjs['subject'].iloc[i]\n",
    "    montage = subjs['montage'].iloc[i]\n",
    "    monopol_chans = RAM_helpers.load_elec_info(subject, montage, bipolar=False)\n",
    "    monopol_chans_types = monopol_chans['type']\n",
    "    monopol_chans_types_counts_grids = monopol_chans_types.str.count('G')\n",
    "    monopol_chans_types_counts_grids = sum(np.asarray(monopol_chans_types_counts_grids))\n",
    "    Count_Grids = np.append(Count_Grids, np.array([monopol_chans_types_counts_grids]), axis=0)\n",
    "    del subject\n",
    "    del montage\n",
    "    del monopol_chans\n",
    "    del monopol_chans_types\n",
    "    del monopol_chans_types_counts_grids\n",
    "    \n",
    "subjs_grids = subjs.iloc[np.nonzero(Count_Grids)]\n",
    "subjs_grids = subjs_grids.reset_index(drop=True)\n",
    "del subjs\n",
    "th1subjs = subjs_grids\n",
    "th1subjs['task'] = 'RAM_TH1'\n",
    "th1subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000., 1000., 1000., 1600., 1000., 1000., 1000., 1000.,  500.,\n",
       "       1000., 1000., 1000., 1000., 1000.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find minimum sampling frequency\n",
    "Samp_Freq_All = np.empty(0)\n",
    "for i in range(0,np.shape(th1subjs)[0],1):\n",
    "    subject = th1subjs['subject'].iloc[i]\n",
    "    montage = th1subjs['montage'].iloc[i]\n",
    "    events = RAM_helpers.load_subj_events('RAM_TH1', subject, montage, as_df=True, remove_no_eeg=True)\n",
    "    events_short = events.iloc[[0]]\n",
    "    monopol_chans = RAM_helpers.load_elec_info(subject, montage, bipolar=False)\n",
    "    eeg = RAM_helpers.load_eeg(events_short, rel_start_ms=0, rel_stop_ms=1500, buf_ms=1000, elec_scheme=monopol_chans, noise_freq=[58., 62.], resample_freq=None, pass_band=None, use_mirror_buf=False, demean=True, do_average_ref=True)\n",
    "    Samp_Freq_All = np.append(Samp_Freq_All, np.array([float(eeg.samplerate)]), axis=0)\n",
    "    del subject\n",
    "    del montage\n",
    "    del events\n",
    "    del events_short\n",
    "    del monopol_chans\n",
    "    del eeg\n",
    "    \n",
    "Samp_Freq_All\n",
    "np.unique(Samp_Freq_All)\n",
    "Samp_Freq = np.min(np.unique(Samp_Freq_All))\n",
    "Samp_Freq_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:23<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:01:04<00:00, 122.14s/it]\n",
      "100%|██████████| 29/29 [1:02:26<00:00, 129.17s/it]\n",
      "100%|██████████| 9/9 [15:51<00:00, 105.75s/it]\n",
      "100%|██████████| 116/116 [05:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [39:13<00:00, 39.23s/it] \n",
      "100%|██████████| 32/32 [23:40<00:00, 44.38s/it]\n",
      "100%|██████████| 31/31 [23:49<00:00, 46.10s/it]\n",
      "100%|██████████| 5/5 [02:54<00:00, 34.85s/it]\n",
      "100%|██████████| 6/6 [04:22<00:00, 43.75s/it]\n",
      "100%|██████████| 5/5 [02:57<00:00, 35.46s/it]\n",
      "100%|██████████| 76/76 [05:32<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [3:02:04<00:00, 242.77s/it]  \n",
      "100%|██████████| 20/20 [1:19:38<00:00, 238.93s/it]\n",
      "100%|██████████| 36/36 [2:26:48<00:00, 244.67s/it]  \n",
      "100%|██████████| 4/4 [15:37<00:00, 234.31s/it]\n",
      "100%|██████████| 4/4 [16:01<00:00, 240.25s/it]\n",
      "100%|██████████| 4/4 [16:16<00:00, 244.05s/it]\n",
      "100%|██████████| 84/84 [04:43<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [1:42:53<00:00, 192.91s/it]\n",
      "100%|██████████| 33/33 [1:38:59<00:00, 179.99s/it]\n",
      "100%|██████████| 23/23 [1:14:04<00:00, 193.26s/it]\n",
      "100%|██████████| 25/25 [1:22:13<00:00, 197.35s/it]\n",
      "100%|██████████| 8/8 [22:02<00:00, 165.37s/it]\n",
      "100%|██████████| 4/4 [12:08<00:00, 182.17s/it]\n",
      "100%|██████████| 5/5 [15:04<00:00, 180.97s/it]\n",
      "100%|██████████| 4/4 [06:04<00:00, 91.07s/it]\n",
      "100%|██████████| 4/4 [12:03<00:00, 180.79s/it]\n",
      "100%|██████████| 4/4 [12:01<00:00, 180.34s/it]\n",
      "100%|██████████| 128/128 [04:54<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [49:53<00:00, 65.07s/it] \n",
      "100%|██████████| 26/26 [27:59<00:00, 64.60s/it]\n",
      "100%|██████████| 28/28 [31:33<00:00, 67.61s/it]\n",
      "100%|██████████| 19/19 [20:56<00:00, 66.11s/it]\n",
      "100%|██████████| 6/6 [06:21<00:00, 63.63s/it]\n",
      "100%|██████████| 4/4 [04:14<00:00, 63.52s/it]\n",
      "100%|██████████| 5/5 [01:04<00:00, 12.99s/it]\n",
      "100%|██████████| 76/76 [03:38<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [1:01:13<00:00, 118.48s/it]\n",
      "100%|██████████| 16/16 [30:44<00:00, 115.29s/it]\n",
      "100%|██████████| 12/12 [23:56<00:00, 119.71s/it]\n",
      "100%|██████████| 56/56 [02:01<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [13:17<00:00, 26.58s/it]\n",
      "100%|██████████| 12/12 [05:03<00:00, 25.30s/it]\n",
      "100%|██████████| 8/8 [02:56<00:00, 22.00s/it]\n",
      "100%|██████████| 7/7 [02:51<00:00, 24.48s/it]\n",
      "100%|██████████| 5/5 [02:04<00:00, 24.94s/it]\n",
      "100%|██████████| 126/126 [05:48<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [1:48:52<00:00, 120.97s/it]\n",
      "100%|██████████| 56/56 [1:48:43<00:00, 116.50s/it]\n",
      "100%|██████████| 15/15 [28:09<00:00, 112.66s/it]\n",
      "100%|██████████| 125/125 [04:46<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:45<00:00, 45.08s/it]\n",
      "100%|██████████| 4/4 [00:42<00:00, 10.71s/it]\n",
      "100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n",
      "100%|██████████| 4/4 [01:25<00:00, 21.45s/it]\n",
      "100%|██████████| 64/64 [02:24<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [16:17<00:00, 48.88s/it]\n",
      "100%|██████████| 21/21 [16:16<00:00, 46.49s/it]\n",
      "100%|██████████| 5/5 [03:49<00:00, 45.89s/it]\n",
      "100%|██████████| 5/5 [02:18<00:00, 27.78s/it]\n",
      "100%|██████████| 92/92 [03:16<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [1:32:19<00:00, 117.86s/it]\n",
      "100%|██████████| 29/29 [49:44<00:00, 102.90s/it]\n",
      "100%|██████████| 90/90 [05:17<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [1:25:52<00:00, 125.67s/it]\n",
      "100%|██████████| 29/29 [49:05<00:00, 101.57s/it] \n",
      " 42%|████▏     | 8/19 [10:28<15:56, 86.92s/it]"
     ]
    }
   ],
   "source": [
    "for i_subj in range(0, len(th1subjs), 1): \n",
    "    \n",
    "    subject = th1subjs['subject'].iloc[i_subj]\n",
    "    montage = th1subjs['montage'].iloc[i_subj]\n",
    "    events_tmp = RAM_helpers.load_subj_events('RAM_TH1', subject, montage, as_df=True, remove_no_eeg=True)\n",
    "    events_short = events_tmp.iloc[[0]]\n",
    "    monopol_chans = RAM_helpers.load_elec_info(subject, montage, bipolar=False)\n",
    "    eeg = RAM_helpers.load_eeg(events_short, rel_start_ms=0, rel_stop_ms=1500, buf_ms=1000, elec_scheme=monopol_chans, noise_freq=[58., 62.], resample_freq=None, pass_band=None, use_mirror_buf=False, demean=True, do_average_ref=True)\n",
    "    fs = np.array([float(eeg.samplerate)])\n",
    "\n",
    "    dd1 = defaultdict(list)\n",
    "    dd2 = defaultdict(list)\n",
    "\n",
    "    # load events, find session available\n",
    "    json_events = RAM_helpers_New.load_subj_events_T('RAM_TH1', subject, '0', use_json=True)\n",
    "    sessions_avail = np.unique(json_events.session)\n",
    "\n",
    "\n",
    "    for sesh in sessions_avail:\n",
    "        sess_events = np.where(json_events.session == sesh)\n",
    "        sess_idx = sess_events[0][0]\n",
    "        eegfile = json_events[sess_idx].eegfile\n",
    "        log_file = eegfile.split('ephys')[0] + 'behavioral/current_source/logs/session_log.txt'\n",
    "        eeg_events = json_events[json_events.eegfile==eegfile]\n",
    "        log = open(log_file, 'r')\n",
    "\n",
    "        strs_START = ['TRIAL_NAVIGATION_STARTED']\n",
    "        strs_END = ['TRIAL_NAVIGATION_ENDED']\n",
    "\n",
    "        ms_times_start = []\n",
    "        ms_times_end = []\n",
    "        item_names = []\n",
    "        for line in log.readlines():\n",
    "            line = line.replace('\\r','')\n",
    "            tokens = line[:-1].split('\\t')\n",
    "            if len(tokens) > 1:\n",
    "                if tokens[3] in strs_START:\n",
    "                    ms_times_start.append(float(tokens[0]))\n",
    "                if tokens[3] in strs_END:\n",
    "                    ms_times_end.append(float(tokens[0]))\n",
    "\n",
    "        #start\n",
    "        events_ms_times = eeg_events.mstime\n",
    "        events_eeg_offsets = eeg_events.eegoffset\n",
    "        lr=LR(fit_intercept=True)\n",
    "        lr.fit(X=events_ms_times.reshape(-1, 1), y=events_eeg_offsets.reshape(-1, 1))    \n",
    "        target_offsets_start = lr.predict(np.array(ms_times_start).reshape(-1,1))\n",
    "        target_offsets_end = lr.predict(np.array(ms_times_end).reshape(-1,1))\n",
    "\n",
    "        for trial, offset in enumerate(target_offsets_start):\n",
    "            # CREATE DATAFRAME\n",
    "            info_for_df1 = {'subject': subject,\n",
    "                           'eegoffset': int(target_offsets_start[trial]),\n",
    "                           'mstime': ms_times_start[trial],\n",
    "                           'type': 'TRIAL_NAVIGATION_STARTED',\n",
    "                           'eegfile': eegfile,\n",
    "                           'experiment': 'TH1',\n",
    "                           'session': sesh}\n",
    "\n",
    "            info_for_df2 = {'subject': subject,\n",
    "                           'eegoffset': int(target_offsets_end[trial]),\n",
    "                           'mstime': ms_times_end[trial],\n",
    "                           'type': 'TRIAL_NAVIGATION_ENDED',\n",
    "                           'eegfile': eegfile,\n",
    "                           'experiment': 'TH1',\n",
    "                           'session': sesh}\n",
    "\n",
    "            for key, value in info_for_df1.items():\n",
    "                dd1[key].append(value)\n",
    "            for key, value in info_for_df2.items():\n",
    "                dd2[key].append(value)\n",
    "            df1 = pd.DataFrame(data = dd1)\n",
    "            df2 = pd.DataFrame(data = dd2)\n",
    "\n",
    "\n",
    "\n",
    "    self = SimpleNamespace()\n",
    "    # whether to load bipolar pairs of electrodes or monopolar contacts\n",
    "    self.bipolar = False\n",
    "\n",
    "    # This will load eeg and compute the average reference before computing power. Recommended if bipolar = False.\n",
    "    self.mono_avg_ref = True\n",
    "\n",
    "    # power computation settings\n",
    "    #self.start_time = 0\n",
    "    self.start_time = 0\n",
    "    self.end_time = 1500\n",
    "    self.wave_num = 5\n",
    "    self.buf_ms = 1000\n",
    "    self.noise_freq = [58., 62.]\n",
    "    #self.resample_freq = None\n",
    "    #Anup changed here\n",
    "    self.resample_freq = 500.\n",
    "    self.log_power = True\n",
    "    self.freqs = np.logspace(np.log10(3), np.log10(40), 200)\n",
    "    self.mean_over_time = True\n",
    "    self.time_bins = None\n",
    "    self.use_mirror_buf = False\n",
    "    self.pool = None\n",
    "\n",
    "    # load electrode info\n",
    "    self.subject = subject\n",
    "    self.montage = montage\n",
    "    self.elec_info = RAM_helpers.load_elec_info(self.subject, self.montage, self.bipolar)\n",
    "\n",
    "    arr_tmp = np.array(df1['eegoffset']) + np.round((np.array(df2['eegoffset']) - np.array(df1['eegoffset']))/2) - (fs/1000)*750\n",
    "    arr_int = arr_tmp.astype(int)\n",
    "    events_for_computation = df1\n",
    "    events_for_computation['eegoffset'] = arr_int\n",
    "    events_for_computation['type'] = 'TRIAL_NAVIGATION'\n",
    "\n",
    "    # compute power with RAM_helper function\n",
    "    subject_data = RAM_helpers.compute_power(events_for_computation,\n",
    "                                             self.freqs,\n",
    "                                             self.wave_num,\n",
    "                                             self.start_time,\n",
    "                                             self.end_time,\n",
    "                                             buf_ms=self.buf_ms,\n",
    "                                             cluster_pool=self.pool,\n",
    "                                             log_power=self.log_power,\n",
    "                                             noise_freq=self.noise_freq,\n",
    "                                             elec_scheme=self.elec_info,\n",
    "                                             resample_freq=self.resample_freq,\n",
    "                                             do_average_ref=self.mono_avg_ref,\n",
    "                                             mean_over_time=self.mean_over_time,\n",
    "                                             use_mirror_buf=self.use_mirror_buf,\n",
    "                                             loop_over_chans=True)\n",
    "\n",
    "\n",
    "    # default frequency settings for identifying peaks\n",
    "    self.freqs = np.logspace(np.log10(3), np.log10(40), 200)\n",
    "    self.bipolar = False\n",
    "    self.start_time = 0\n",
    "    self.end_time = 1500\n",
    "    self.mono_avg_ref = True\n",
    "    self.hilbert_start=0\n",
    "    self.hilbert_end=1500\n",
    "\n",
    "    # window size to find clusters (in Hz)\n",
    "    self.cluster_freq_range = 2.\n",
    "\n",
    "    # D: depths, G: grids, S: strips\n",
    "    self.elec_types_allowed = ['G']\n",
    "\n",
    "    # spatial distance considered near (mm)\n",
    "    self.min_elec_dist = 25.\n",
    "\n",
    "    # If True, osciallation clusters can't cross hemispheres\n",
    "    self.separate_hemis = True\n",
    "\n",
    "    # number of electrodes needed to be considered a cluster\n",
    "    self.min_num_elecs = 6\n",
    "\n",
    "    # elec_info column from which to extract x,y,z coordinates\n",
    "    self.elec_pos_column = ''\n",
    "\n",
    "\n",
    "    xyz = self.elec_info[['{}{}'.format(self.elec_pos_column, coord) for coord in ['tal.x', 'tal.y', 'tal.z']]].values\n",
    "    if self.separate_hemis:\n",
    "        if 'Loc1' in self.elec_info:\n",
    "            xyz[self.elec_info['Loc1']=='Left Cerebrum', 0] -= 100\n",
    "        else:\n",
    "            xyz[xyz[:, 0] < 0, 0] -= 100\n",
    "    elec_dists = squareform(pdist(xyz))\n",
    "\n",
    "    # figure out which pairs of electrodes are closer than the threshold\n",
    "    near_adj_matr = (elec_dists < self.min_elec_dist) & (elec_dists > 0.)\n",
    "    allowed_elecs = np.array([e in self.elec_types_allowed for e in self.elec_info['type']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # default frequency settings for identifying peaks\n",
    "    self.freqs = np.logspace(np.log10(3), np.log10(40), 200)\n",
    "    self.bipolar = False\n",
    "    self.start_time = 0\n",
    "    self.end_time = 1500\n",
    "    self.mono_avg_ref = True\n",
    "    self.hilbert_start=0\n",
    "    self.hilbert_end=1500\n",
    "\n",
    "    # window size to find clusters (in Hz)\n",
    "    self.cluster_freq_range = 2.\n",
    "\n",
    "    # D: depths, G: grids, S: strips\n",
    "    self.elec_types_allowed = ['G']\n",
    "\n",
    "    # spatial distance considered near (mm)\n",
    "    self.min_elec_dist = 25.\n",
    "\n",
    "    # If True, osciallation clusters can't cross hemispheres\n",
    "    self.separate_hemis = True\n",
    "\n",
    "    # number of electrodes needed to be considered a cluster\n",
    "    self.min_num_elecs = 6\n",
    "\n",
    "    # elec_info column from which to extract x,y,z coordinates\n",
    "    self.elec_pos_column = ''\n",
    "    self.elec_pos_type = ''\n",
    "\n",
    "\n",
    "    xyz = self.elec_info[['{}{}'.format(self.elec_pos_column, coord) for coord in ['tal.x', 'tal.y', 'tal.z']]].values\n",
    "    if self.separate_hemis:\n",
    "        if 'Loc1' in self.elec_info:\n",
    "            xyz[self.elec_info['Loc1']=='Left Cerebrum', 0] -= 100\n",
    "        else:\n",
    "            xyz[xyz[:, 0] < 0, 0] -= 100\n",
    "    elec_dists = squareform(pdist(xyz))\n",
    "\n",
    "    # figure out which pairs of electrodes are closer than the threshold\n",
    "    near_adj_matr = (elec_dists < self.min_elec_dist) & (elec_dists > 0.)\n",
    "    allowed_elecs = np.array([e in self.elec_types_allowed for e in self.elec_info['type']])\n",
    "\n",
    "    # normalized power spectra\n",
    "    event_dim_str='event'\n",
    "    self.subject_data = subject_data\n",
    "    sessions = self.subject_data[event_dim_str].data['session']\n",
    "    norm_spectra = np.empty(self.subject_data.shape)\n",
    "    uniq_sessions = np.unique(sessions)\n",
    "    for sess in uniq_sessions:\n",
    "        sess_inds = sessions == sess\n",
    "\n",
    "        m = np.mean(self.subject_data[sess_inds], axis=1)\n",
    "        m = np.mean(m, axis=0)\n",
    "        s = np.std(self.subject_data[sess_inds], axis=1)\n",
    "        s = np.mean(s, axis=0)\n",
    "        norm_spectra[sess_inds] = (self.subject_data[sess_inds] - m) / s\n",
    "    p_spect = norm_spectra\n",
    "\n",
    "    # Compute mean power spectra across events, and then find where each electrode has peaks\n",
    "    mean_p_spect = np.mean(p_spect, axis=self.subject_data.get_axis_num('event'))\n",
    "    peaks = par_find_peaks_by_chan2(mean_p_spect, self.freqs, 1)\n",
    "    # now that we know at which each electrode has peaks, compute clusters of electrodes that exhibit peaks at\n",
    "    # similar frequencies and are close enough together\n",
    "    steplength=5;windowLength=15;\n",
    "    distance=25;\n",
    "    CLUSTERS=[]\n",
    "    peaks[:, ~allowed_elecs] = False\n",
    "    peakid=peaks\n",
    "    windows=np.stack([[i,windowLength+i] for i in range(0,201-steplength,steplength)])\n",
    "    for ire in range(10):\n",
    "        peak_counts=np.sum(peakid,axis=1)\n",
    "        window_counts=np.array([sum(peak_counts[w[0]:w[1]]) for w in windows])\n",
    "        peak_window=np.argmax(window_counts)\n",
    "        near_this_ev = near_adj_matr.copy()\n",
    "        peak_within_window=np.any(peakid[windows[peak_window,0]:windows[peak_window,1]],axis=0)\n",
    "        near_this_ev[~peak_within_window,:] = False\n",
    "        near_this_ev[:, ~peak_within_window] = False\n",
    "        # use targan algorithm to find the clusters\n",
    "        graph = {}\n",
    "        for elec, row in enumerate(near_this_ev):\n",
    "            graph[elec] = np.where(row)[0]\n",
    "        groups = tarjan(graph)\n",
    "        #choose the connected componet with most electrodes as seed\n",
    "        clusterSeed=sorted(sorted(groups,key=lambda a:-len(a))[0])\n",
    "        #make it a dictionary\n",
    "        window_true=np.zeros((200),dtype=bool)\n",
    "        window_true[windows[peak_window,0]:windows[peak_window,1]]=True\n",
    "        cluster={}\n",
    "        if len(clusterSeed)>1:\n",
    "            for i in clusterSeed:\n",
    "                peak_freq=np.squeeze(np.where(np.logical_and(peakid[:,i],window_true))[0][0])\n",
    "                cluster[i]=peak_freq\n",
    "                peakid[peak_freq,i]=False\n",
    "        if len(cluster)>1:\n",
    "            for ire2 in range(10):\n",
    "                for i in range(len(near_adj_matr)):\n",
    "                    if i not in cluster:\n",
    "                        near_freqS=np.squeeze(list(cluster.values()))[near_adj_matr[i,list(cluster.keys())]]\n",
    "                        if len(near_freqS)>1:\n",
    "                            window_true=np.zeros((200),dtype=bool)\n",
    "                            window_true[windows[peak_window,0]:windows[peak_window,1]]=True\n",
    "                            near_freq=int(np.median(near_freqS))\n",
    "                            electrode_frequency=np.where(peakid[:,i])[0]\n",
    "                            if np.any(np.abs(electrode_frequency-near_freq)<15):\n",
    "                                peak_freq=np.array(min(electrode_frequency, key=lambda x:abs(x-near_freq)))\n",
    "                                cluster[i]=peak_freq\n",
    "                                peakid[peak_freq,i]=False\n",
    "            CLUSTERS.append(cluster)\n",
    "    for i in CLUSTERS:\n",
    "        for j in i:\n",
    "            i[j]=self.freqs[i[j]]\n",
    "    res={}\n",
    "    i=0\n",
    "    while i<(len(CLUSTERS)):\n",
    "        if len(CLUSTERS[i])>3:\n",
    "            res[i]=CLUSTERS[i]\n",
    "        i+=1\n",
    "    cluster_count = 0\n",
    "    df_list = []\n",
    "\n",
    "    for i in res.keys():\n",
    "        cluster_count += 1\n",
    "        col_name = 'cluster{}'.format(cluster_count)\n",
    "        cluster_df = pd.DataFrame(data=np.full(shape=(peaks.shape[1]), fill_value=np.nan), columns=[col_name])\n",
    "        for j in res[i]:\n",
    "            cluster_df.iloc[j]=res[i][j]\n",
    "        df_list.append(cluster_df)\n",
    "    df = None\n",
    "    if df_list:\n",
    "        df = pd.concat(df_list, axis='columns')\n",
    "        df = pd.concat([df,self.elec_info], axis='columns')\n",
    "        # add a tag to localization. avg.region for new patients, Loc3 for old\n",
    "        if 'avg.region' in self.elec_info:\n",
    "            df['tag'] = self.elec_info['avg.region']\n",
    "        else:\n",
    "            df['tag'] = self.elec_info['Loc3']\n",
    "\n",
    "    self.res = {}        \n",
    "    self.res['clusters'] = df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    events = events_for_computation\n",
    "    self.task = th1subjs.iloc[0][2]\n",
    "    Resample = Samp_Freq\n",
    "    task_phase = 'TRIAL_NAVIGATION'\n",
    "\n",
    "    # initialize eeg and res\n",
    "    uniq_sessions = np.unique(self.subject_data.event.data['session'])\n",
    "    if self.subject[:2]=='FR':\n",
    "        noise=[48., 52.]\n",
    "    else:\n",
    "        noise=[58., 62.]\n",
    "    buf=1000\n",
    "\n",
    "    eeg=RAM_helpers.load_eeg(events, self.hilbert_start, self.hilbert_end, buf_ms=buf, elec_scheme=self.elec_info, noise_freq=noise, resample_freq=None, pass_band=None, use_mirror_buf=False, demean=True, do_average_ref=True)\n",
    "    eeg = ResampleFilter(eeg, Resample).filter()\n",
    "\n",
    "    print('Band pass EEG')\n",
    "    time_frame_start=int((buf/1000)*Resample)\n",
    "    time_frame_end=int(Resample*(self.hilbert_end-self.hilbert_start+buf)/1000)\n",
    "    eeg=eeg.transpose('channel', 'event', 'time')\n",
    "    thetas = np.radians(np.arange(0, 360, 5))\n",
    "    rs = np.radians(np.arange(0, 18, 1))\n",
    "    theta_r = np.stack([(x, y) for x in thetas for y in rs])\n",
    "    params = np.stack([theta_r[:, 1] * np.cos(theta_r[:, 0]), theta_r[:, 1] * np.sin(theta_r[:, 0])], -1)\n",
    "    f=circ_lin_regress\n",
    "    allowed_elecs = np.array([e in self.elec_types_allowed for e in self.elec_info['type']])\n",
    "    i=1\n",
    "    print('Traveling wave analysis')\n",
    "    while 'cluster{}'.format(i) in self.res['clusters'].columns:\n",
    "        res={}\n",
    "        clusterphase=[]\n",
    "        clusterpower=[]\n",
    "        clustereeg=[]\n",
    "        cluster='cluster{}'.format(i)\n",
    "        for j in range(len(self.res['clusters'])):\n",
    "            freq=self.res['clusters'][cluster][j]\n",
    "            if ~np.isnan(freq):\n",
    "                feeg=RAM_helpers.band_pass_eeg(eeg[j], [freq *.85, freq/.85],order=3)\n",
    "                clusterphase.append(np.angle(hilbert(feeg, N=feeg.shape[-1], axis=-1)))\n",
    "                clusterpower.append(np.abs(hilbert(feeg, N=feeg.shape[-1], axis=-1)))\n",
    "                clustereeg.append(feeg)\n",
    "        res['power']=np.stack(clusterpower)[:,:,time_frame_start:time_frame_end].astype('float32') \n",
    "        res['phase']=np.stack(clusterphase)[:,:,time_frame_start:time_frame_end].astype('float32') \n",
    "        res['eeg']=np.stack(clustereeg)[:,:,time_frame_start:time_frame_end].astype('float32') \n",
    "        \n",
    "        xyz_cluster = self.elec_info[['{}{}'.format(self.elec_pos_column, coord) for coord in ['tal.x', 'tal.y', 'tal.z']]].values\n",
    "        xyz_cluster = xyz_cluster[~np.isnan(self.res['clusters'][cluster])]\n",
    "        xyz_all_grid=self.elec_info[['{}{}'.format(self.elec_pos_column, coord) for coord in ['tal.x', 'tal.y', 'tal.z']]].values[np.squeeze(self.elec_info[['{}{}'.format(self.elec_pos_type, elec_type) for elec_type in ['type']]].values == 'G'), :]\n",
    "        pca = PCA(n_components=3)\n",
    "\n",
    "        xyz_all_grid -= np.mean(xyz_all_grid, axis=0)\n",
    "        xyz_cluster -= np.mean(xyz_cluster, axis=0)\n",
    "\n",
    "        xyz_2D_map = pca.fit_transform(xyz_all_grid)[:, :2]\n",
    "        xyz_PCA = pca.transform(xyz_cluster)[:, :2]\n",
    "        \n",
    "        elec_dists = squareform(pdist(xyz_PCA))\n",
    "        near_adj_matr = (elec_dists < 25.)\n",
    "        local_angle={}\n",
    "        local_sf={}\n",
    "        local_rs={}\n",
    "        local_off={}\n",
    "        for j in tqdm(range(0,len(xyz_cluster))):\n",
    "            if sum(near_adj_matr[j])>3:\n",
    "                norm_coords = xyz_PCA[near_adj_matr[j],:]\n",
    "                num_iters = int(res['phase'][near_adj_matr[j]].T.shape[0])\n",
    "                data_as_list = zip(res['phase'][near_adj_matr[j]].T,np.array([norm_coords]*num_iters), [theta_r]*num_iters, [params]*num_iters)\n",
    "                res_as_list = Parallel(n_jobs=40, verbose=0)(delayed(f)(x[0], x[1], x[2], x[3]) for x in data_as_list)\n",
    "                local_angle[j]=np.stack([x[0] for x in res_as_list], axis=0).astype('float32') \n",
    "                local_sf[j]=np.stack([x[1] for x in res_as_list], axis=0).astype('float32') \n",
    "                local_rs[j]=np.stack([x[2] for x in res_as_list], axis=0).astype('float32')\n",
    "                local_off[j]=np.stack([x[3] for x in res_as_list], axis=0).astype('float32')  \n",
    "        res['direction'] = local_angle \n",
    "        res['spatial_freuency']= local_sf\n",
    "        res['rs']= local_rs\n",
    "        res['offs']= local_off\n",
    "        if cluster not in self.res:\n",
    "            self.res[cluster]={}\n",
    "        self.res[cluster][task_phase]=res\n",
    "        i+=1\n",
    "\n",
    "    with open('/home1/anup.das/Results/tw_th_files_grids_2D/tw_files/tw_nav_files/tw_subj_' + subject + '_grids_2D_fine_CPCAM.pkl', 'wb') as f:\n",
    "        pickle.dump(self.res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
